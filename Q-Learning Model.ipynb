{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from environment import TrafficEnv\n",
    "from ml_controller import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(Q, epsilon, num_actions):\n",
    "    def policy_fn(observation):\n",
    "        actions = np.ones(num_actions, dtype=float) * epsilon / num_actions\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        actions[best_action] += (1.0 - epsilon)\n",
    "        return actions\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(Q, env, num_episodes, group_size, disc_factor=0.95, alpha=0.3, epsilon=0.001):\n",
    "    stats = {'episode_lengths': np.zeros(num_episodes)}\n",
    "    \n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.num_actions)\n",
    "    avg_len = 0\n",
    "    \n",
    "    for i_ep  in range(num_episodes):\n",
    "        # Display episode number every so often\n",
    "        if (i_ep + 1) % group_size == 0:\n",
    "            prev_avg = avg_len\n",
    "            avg_len = sum(stats['episode_lengths'][i_ep - group_size - 1:i_ep - 1]) / group_size\n",
    "            avg_diff = avg_len - prev_avg\n",
    "            print(\"\\rEpisode {}/{}, Latest ep len {}, Average change {}\".format(\n",
    "                i_ep + 1, num_episodes, avg_len, avg_diff), end=\"\")\n",
    "        \n",
    "        prev_state = tuple(env.reset())\n",
    "        \n",
    "        for t in itertools.count():\n",
    "            action_probs = policy(prev_state)\n",
    "            action = np.random.choice(np.arange(env.num_actions), p=action_probs)\n",
    "            reward, done = env.step(action)\n",
    "            next_state = tuple(env.state)\n",
    "            \n",
    "            stats['episode_lengths'][i_ep] = t\n",
    "            \n",
    "            best_next_action = np.argmax(Q[next_state])\n",
    "            td_target = reward + disc_factor * Q[next_state][best_next_action]\n",
    "            td_delta = td_target - Q[prev_state][action]\n",
    "            Q[prev_state][action] += alpha * td_delta\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            prev_state = next_state\n",
    "    return Q, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd():\n",
    "    return np.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cars = 10\n",
    "episode_length = 30000\n",
    "group_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TrafficEnv()\n",
    "controller = Controller(env, max_cars)\n",
    "\n",
    "# Q maps the state -> (action -> action-value)\n",
    "Q = defaultdict(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30000/30000, Latest ep len 156.307, Average change -0.18800000000001662"
     ]
    }
   ],
   "source": [
    "Q, stats = q_learning(Q, controller, episode_length, group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_len = stats['episode_lengths']\n",
    "avg_ep_len_arr = []\n",
    "for ep_range in range(0, episode_length, group_size):\n",
    "    avg_ep_len = sum(ep_len[ep_range:ep_range+group_size]) / group_size\n",
    "    avg_ep_len_arr.append(avg_ep_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c7166f5b38>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(avg_ep_len_arr))), avg_ep_len_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Q, open('policy.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_env = TrafficEnv()\n",
    "sim = Controller(sim_env, max_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lane state is (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "The state is (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "The action returns are [-5.026785804476649, -5.081045001553208, -4.821658366178063, -4.964930978551738, -4.954085174812419, -3.901606279309073]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0)\n",
      "The state is (0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0)\n",
      "The action returns are [-4.704609018835177, -4.477606492348695, -3.8565468513219687, -4.716920340134989, -4.462952306413799, -4.6406276136683]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0)\n",
      "The state is (1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 5.0)\n",
      "The action returns are [-1.5166499999999998, -1.497808562486395, -1.190270105757894, -0.8999999999999999, -0.6276987978218437, -1.2855]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0)\n",
      "The state is (2.0, 0.0, 3.0, 1.0, 4.0, 1.0, 2.0)\n",
      "The action returns are [-0.4709999999999999, -0.8848799670235, -0.4769605029697105, 0.0, 0.0, 0.0]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0)\n",
      "The state is (2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0)\n",
      "The action returns are [-0.3, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0)\n",
      "The state is (3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0)\n",
      "The action returns are [-1.2, -0.8999999999999999, -0.8999999999999999, -0.81, -1.0050752665664948, -0.5630870476697042]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1)\n",
      "The state is (4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 1.0)\n",
      "The action returns are [-1.2, -0.7709999999999999, -0.6, -0.6, -0.8999999999999999, -0.041922333052918065]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (2, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1)\n",
      "The state is (5.0, 1.0, 3.0, 4.0, 6.0, 4.0, 5.0)\n",
      "The action returns are [-0.9531818166201026, -1.4358575999999998, -0.7740557894521782, -0.38999999999999996, -0.6435, -0.590943]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (2, 2, 2, 0, 0, 0, 2, 1, 1, 1, 1, 1)\n",
      "The state is (6.0, 0.0, 4.0, 3.0, 7.0, 2.0, 5.0)\n",
      "The action returns are [-0.33545017499999996, -0.8999999999999999, -0.6549765, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (3, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1)\n",
      "The state is (7.0, 1.0, 4.0, 2.0, 8.0, 2.0, 3.0)\n",
      "The action returns are [-0.2812318871961425, -0.8999999999999999, -0.8999999999999999, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 0, 0, 2, 2, 1, 1, 0, 0)\n",
      "The state is (8.0, 1.0, 5.0, 1.0, 10.0, 2.0, 3.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (3, 3, 3, 1, 0, 0, 2, 2, 2, 1, 0, 0)\n",
      "The state is (9.0, 1.0, 6.0, 1.0, 10.0, 2.0, 3.0)\n",
      "The action returns are [0.4537467740182769, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (4, 3, 3, 1, 0, 0, 2, 2, 2, 1, 1, 0)\n",
      "The state is (10.0, 1.0, 6.0, 2.0, 11.0, 3.0, 0.0)\n",
      "The action returns are [0.3612294953127694, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 0, 0, 3, 2, 2, 1, 1, 0)\n",
      "The state is (8.0, 1.0, 7.0, 2.0, 11.0, 3.0, 0.0)\n",
      "The action returns are [0.2551365711138608, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 2, 1, 1, 1, 0, 3, 2, 2, 1, 1, 1)\n",
      "The state is (5.0, 2.0, 7.0, 3.0, 9.0, 4.0, 0.0)\n",
      "The action returns are [-1.09383322425, -1.0481412138735, -0.8999999999999999, -1.2, 0.16725938889717684, -0.9570000000000001]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (1, 1, 0, 1, 1, 1, 3, 2, 2, 2, 1, 1)\n",
      "The state is (2.0, 3.0, 7.0, 4.0, 7.0, 5.0, 0.0)\n",
      "The action returns are [-0.3, -0.4611300750000001, -0.21578250000000002, -0.6, 0.44177384362608957, -0.54015]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 0, 0, 1, 1, 1, 3, 2, 2, 2, 1, 1)\n",
      "The state is (1.0, 3.0, 7.0, 4.0, 6.0, 5.0, 4.0)\n",
      "The action returns are [-0.3, -0.8999999999999999, -0.3, -0.6, 0.3124459907281729, -0.6]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 0, 0, 1, 1, 1, 2, 2, 2, 2, 1, 1)\n",
      "The state is (1.0, 3.0, 6.0, 4.0, 5.0, 5.0, 4.0)\n",
      "The action returns are [-0.6, -0.38549999999999995, -0.45299999999999996, -0.81, 0.3077142148917026, -0.3]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 0, 0, 1, 1, 1, 2, 1, 2, 2, 2, 1)\n",
      "The state is (1.0, 3.0, 5.0, 5.0, 4.0, 6.0, 4.0)\n",
      "The action returns are [-0.8999999999999999, -0.8999999999999999, -0.593079, -0.8999999999999999, -0.72519731775, -0.72]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 0, 0, 1, 1, 1, 1, 0, 2, 2, 2, 2)\n",
      "The state is (1.0, 3.0, 3.0, 6.0, 2.0, 6.0, 4.0)\n",
      "The action returns are [-0.8999999999999999, -0.465765, -0.5052, 0.0, 0.0, 0.0]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (1, 1, 0, 2, 1, 1, 1, 0, 2, 3, 2, 2)\n",
      "The state is (2.0, 4.0, 3.0, 7.0, 3.0, 8.0, 2.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (1, 1, 1, 2, 2, 1, 1, 0, 2, 3, 3, 2)\n",
      "The state is (3.0, 5.0, 3.0, 8.0, 3.0, 10.0, 3.0)\n",
      "The action returns are [-0.0684028499999999, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 1, 1, 2, 2, 2, 1, 0, 2, 3, 3, 2)\n",
      "The state is (4.0, 6.0, 3.0, 8.0, 4.0, 10.0, 0.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 2, 1, 3, 2, 2, 1, 1, 2, 3, 3, 2)\n",
      "The state is (5.0, 7.0, 4.0, 8.0, 6.0, 11.0, 1.0)\n",
      "The action returns are [0.40667367750000005, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 2, 1, 3, 3, 2, 2, 1, 2, 3, 3, 3)\n",
      "The state is (5.0, 8.0, 5.0, 9.0, 7.0, 12.0, 0.0)\n",
      "The action returns are [-1.0336350375374999, -1.3199999999999998, -0.786, -0.8999999999999999, -0.873, -1.4100000000000001]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (1, 1, 0, 3, 3, 3, 2, 1, 2, 3, 3, 3)\n",
      "The state is (2.0, 9.0, 5.0, 9.0, 5.0, 12.0, 0.0)\n",
      "The action returns are [-0.84015, -0.3, 1.3968191677015216, 0.0, 0.0, 0.0]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (1, 1, 0, 3, 3, 3, 2, 2, 2, 4, 3, 3)\n",
      "The state is (2.0, 9.0, 6.0, 10.0, 6.0, 13.0, 2.0)\n",
      "The action returns are [-0.21450000000000002, -0.8999999999999999, -0.1300774899299999, -0.3, -0.07464899999999997, 0.0]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (1, 1, 1, 3, 3, 3, 2, 1, 1, 4, 4, 3)\n",
      "The state is (3.0, 9.0, 4.0, 11.0, 5.0, 14.0, 2.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (1, 1, 1, 4, 3, 3, 2, 1, 1, 4, 4, 4)\n",
      "The state is (3.0, 10.0, 4.0, 12.0, 5.0, 15.0, 5.0)\n",
      "The action returns are [0.039176229194070045, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 1, 1, 4, 4, 3, 2, 2, 1, 4, 4, 4)\n",
      "The state is (4.0, 11.0, 5.0, 12.0, 7.0, 16.0, 0.0)\n",
      "The action returns are [-2.2081067296574997, -2.04, -2.1271500000000003, -1.86966, -1.8239999999999998, -2.2226999999999997]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (1, 0, 0, 4, 4, 4, 2, 2, 2, 4, 4, 4)\n",
      "The state is (1.0, 12.0, 6.0, 12.0, 5.0, 16.0, 0.0)\n",
      "The action returns are [-0.8564999999999999, -0.6, -0.28855500000000006, -0.6, 0.51, 0.0]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (1, 0, 0, 4, 4, 4, 3, 2, 2, 5, 4, 4)\n",
      "The state is (1.0, 12.0, 7.0, 13.0, 6.0, 17.0, 4.0)\n",
      "The action returns are [-0.8999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 4\n",
      "\n",
      "The lane state is (0, 0, 0, 4, 4, 4, 2, 1, 2, 5, 5, 4)\n",
      "The state is (0.0, 12.0, 5.0, 14.0, 3.0, 18.0, 4.0)\n",
      "The action returns are [-0.6, 0.6, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (1, 0, 0, 5, 4, 4, 2, 1, 2, 5, 5, 4)\n",
      "The state is (1.0, 13.0, 5.0, 14.0, 4.0, 19.0, 1.0)\n",
      "The action returns are [-0.6, 0.801472411229175, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (1, 1, 0, 4, 4, 3, 2, 2, 2, 5, 5, 4)\n",
      "The state is (2.0, 11.0, 6.0, 14.0, 6.0, 18.0, 1.0)\n",
      "The action returns are [-0.84015, 0.9925812289797, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (1, 1, 1, 3, 3, 2, 3, 2, 2, 5, 5, 5)\n",
      "The state is (3.0, 8.0, 7.0, 15.0, 7.0, 16.0, 1.0)\n",
      "The action returns are [-0.8999999999999999, 1.2616535461882123, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (1, 1, 1, 2, 2, 2, 3, 2, 2, 6, 5, 5)\n",
      "The state is (3.0, 6.0, 7.0, 16.0, 7.0, 15.0, 1.0)\n",
      "The action returns are [-0.6, 0.23406, -1.2, -0.6, -0.6, -0.25883999999999996]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 1, 1, 2, 1, 1, 3, 3, 2, 6, 6, 5)\n",
      "The state is (4.0, 4.0, 8.0, 17.0, 9.0, 15.0, 1.0)\n",
      "The action returns are [-0.415819025025, -0.38549999999999995, -1.2, -0.8999999999999999, -0.3, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 1, 1, 1, 1, 0, 3, 3, 2, 6, 6, 5)\n",
      "The state is (4.0, 2.0, 8.0, 17.0, 9.0, 14.0, 1.0)\n",
      "The action returns are [-0.6, -0.3, -0.3, 0.0, 0.0, 0.0]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (2, 1, 1, 1, 0, 0, 3, 3, 2, 6, 6, 6)\n",
      "The state is (4.0, 1.0, 8.0, 18.0, 9.0, 13.0, 5.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (2, 2, 1, 1, 0, 0, 3, 3, 2, 6, 5, 6)\n",
      "The state is (5.0, 1.0, 8.0, 17.0, 10.0, 12.0, 3.0)\n",
      "The action returns are [-0.157585386, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 2, 2, 1, 1, 0, 3, 3, 2, 6, 5, 6)\n",
      "The state is (6.0, 2.0, 8.0, 17.0, 10.0, 13.0, 0.0)\n",
      "The action returns are [-0.47763428741249997, 0.594, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 2, 2, 1, 1, 1, 3, 3, 3, 6, 6, 6)\n",
      "The state is (6.0, 3.0, 9.0, 18.0, 10.0, 14.0, 1.0)\n",
      "The action returns are [-0.6, -0.09000000000000002, -0.6, -0.3, -0.6, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (3, 2, 2, 1, 0, 0, 3, 3, 3, 6, 6, 6)\n",
      "The state is (7.0, 1.0, 9.0, 18.0, 11.0, 13.0, 1.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 5\n",
      "\n",
      "The lane state is (3, 3, 2, 0, 0, 0, 4, 3, 3, 7, 6, 6)\n",
      "The state is (8.0, 0.0, 10.0, 19.0, 13.0, 13.0, 5.0)\n",
      "The action returns are [-0.21450000000000002, -0.3, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 0, 0, 4, 4, 3, 7, 7, 6)\n",
      "The state is (8.0, 1.0, 11.0, 20.0, 14.0, 15.0, 0.0)\n",
      "The action returns are [-0.8999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 0, 0, 4, 4, 3, 7, 7, 7)\n",
      "The state is (8.0, 1.0, 11.0, 21.0, 14.0, 15.0, 2.0)\n",
      "The action returns are [-0.8999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (3, 3, 3, 1, 0, 0, 4, 4, 3, 7, 7, 7)\n",
      "The state is (9.0, 1.0, 11.0, 21.0, 14.0, 15.0, 1.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (3, 3, 3, 1, 0, 0, 4, 4, 3, 8, 7, 7)\n",
      "The state is (9.0, 1.0, 11.0, 22.0, 14.0, 16.0, 1.0)\n",
      "The action returns are [-0.137254781325, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (4, 3, 3, 1, 0, 0, 4, 4, 3, 8, 7, 7)\n",
      "The state is (10.0, 1.0, 11.0, 22.0, 15.0, 16.0, 0.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (4, 4, 3, 1, 0, 0, 4, 4, 4, 8, 8, 7)\n",
      "The state is (11.0, 1.0, 12.0, 23.0, 16.0, 17.0, 1.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (4, 4, 3, 1, 1, 0, 4, 4, 4, 8, 8, 7)\n",
      "The state is (11.0, 2.0, 12.0, 23.0, 16.0, 18.0, 0.0)\n",
      "The action returns are [-0.09590722927500002, -0.8999999999999999, -1.2, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 1, 1, 5, 4, 4, 8, 8, 7)\n",
      "The state is (8.0, 3.0, 13.0, 23.0, 15.0, 18.0, 0.0)\n",
      "The action returns are [-0.7477052625, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (3, 3, 2, 1, 1, 1, 5, 4, 4, 8, 8, 8)\n",
      "The state is (8.0, 3.0, 13.0, 24.0, 15.0, 18.0, 3.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (3, 3, 3, 1, 1, 1, 5, 5, 4, 9, 8, 8)\n",
      "The state is (9.0, 3.0, 14.0, 25.0, 16.0, 19.0, 1.0)\n",
      "The action returns are [0.3, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 3, 3, 2, 1, 1, 5, 5, 5, 9, 9, 8)\n",
      "The state is (9.0, 4.0, 15.0, 26.0, 16.0, 21.0, 0.0)\n",
      "The action returns are [0.33419999999999994, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 2, 2, 2, 2, 1, 6, 5, 5, 9, 9, 9)\n",
      "The state is (7.0, 5.0, 16.0, 27.0, 16.0, 22.0, 0.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (2, 2, 1, 2, 2, 1, 6, 5, 5, 10, 9, 9)\n",
      "The state is (5.0, 5.0, 16.0, 28.0, 15.0, 23.0, 0.0)\n",
      "The action returns are [-0.2927264999999999, -0.8999999999999999, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (1, 1, 1, 2, 2, 1, 6, 6, 5, 10, 9, 9)\n",
      "The state is (3.0, 5.0, 17.0, 28.0, 14.0, 23.0, 0.0)\n",
      "The action returns are [-0.7726050000000001, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 2\n",
      "\n",
      "The lane state is (2, 1, 1, 2, 2, 2, 6, 6, 5, 10, 10, 9)\n",
      "The state is (4.0, 6.0, 17.0, 29.0, 15.0, 24.0, 2.0)\n",
      "The action returns are [-0.84102402375, -0.3, -0.8999999999999999, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (2, 2, 1, 2, 2, 2, 6, 6, 6, 10, 10, 9)\n",
      "The state is (5.0, 6.0, 18.0, 29.0, 16.0, 24.0, 1.0)\n",
      "The action returns are [-0.9879407625, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 3\n",
      "\n",
      "The lane state is (2, 2, 2, 3, 2, 2, 6, 6, 6, 10, 10, 9)\n",
      "The state is (6.0, 7.0, 18.0, 29.0, 16.0, 25.0, 3.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 1\n",
      "\n",
      "The lane state is (3, 2, 2, 3, 2, 2, 7, 6, 6, 10, 10, 10)\n",
      "The state is (7.0, 7.0, 19.0, 30.0, 18.0, 25.0, 1.0)\n",
      "The action returns are [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The lane state is (3, 3, 2, 3, 2, 2, 7, 6, 6, 11, 10, 10)\n",
      "The state is (8.0, 7.0, 19.0, 31.0, 19.0, 26.0, 0.0)\n",
      "The action returns are [0.6855, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "The action taken was 0\n",
      "\n",
      "The model did not last for the full simulation\n",
      "The model survived for 63 seconds\n",
      "Average cars during runtime: 31.857142857142858\n"
     ]
    }
   ],
   "source": [
    "total_cars = 0\n",
    "sim.reset()\n",
    "for _ in range(100):\n",
    "    best_action = np.argmax(Q[sim.state])\n",
    "    print(f'The lane state is {sim.lane_state}')\n",
    "    print(f'The state is {sim.state}')\n",
    "    rewards, done  = sim.step(best_action)\n",
    "    total_cars += sum(sim.lane_state)\n",
    "    print(f'The action returns are {list(Q[sim.state])}')\n",
    "    print(f'The action taken was {best_action}')\n",
    "    print()\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print('The model did not last for the full simulation')\n",
    "print(f'The model survived for {_} seconds')\n",
    "avg_cars = total_cars/_\n",
    "print(f'Average cars during runtime: {avg_cars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
